"""
Agent ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸
==================

LLMManager, VideoAnalysisAgent, PlannerAgent, SupervisorAgent, ActorAgent

ëª¨ë“  ì¶”ë¡ ì€ ì‹¤ì œ LLMìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤. ë”ë¯¸ ì—†ìŒ.
"""

import os
import gc
import json
import base64
import time
import logging
from datetime import datetime
from typing import List, Dict, TypedDict, Optional, Any

import cv2
import numpy as np

from .actions import AVAILABLE_ACTIONS, SCENARIO_ACTIONS, ACTION_PRIORITY


# ê¸°ë³¸ ì„¤ì •
DEFAULT_CONFIG = {
    "VISION_MODEL_PATH": "/data/DJ/models/Qwen2.5-VL-7B-Instruct-q4_k_m.gguf",
    "MM_PROJ_PATH": "/data/DJ/models/Qwen2.5-VL-7B-Instruct-mmproj-f16.gguf",
    "TEXT_MODEL_PATH": "/data/DJ/models/Qwen3-8B-Q4_K_M.gguf",
    "ANALYSIS_DURATION": 3,
    "N_GPU_LAYERS": -1,
    "N_CTX": 32768,
    "N_THREADS": 16,
    "N_BATCH": 512,
    "MAIN_GPU": 2,
}


class VideoAnalysisState(TypedDict, total=False):
    """ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    video_path: str
    trigger_timestamp: float
    timestamp: str
    
    # ì‹¤ì‹œê°„ ëª¨ë“œìš©
    realtime_frames: List
    
    # ë¶„ì„ ê²°ê³¼
    frame_analyses: List[Dict]
    context_history: str
    final_situation_description: str
    encoded_frames: List[str]
    
    # ë¶„ë¥˜ ê²°ê³¼
    classification_report: str
    situation_type: str
    severity_level: str
    classification_reasoning: str
    
    # Supervisor ê´€ë ¨
    supervisor_instruction_to_planner: str
    supervisor_plan_review: str
    plan_approved: bool
    review_feedback: str
    plan_retry_count: int
    
    # Planner ê´€ë ¨
    planner_report: str
    agent_plan: Dict
    
    # Actor ê´€ë ¨
    actor_execution_results: List[Dict]
    
    # ì‹œìŠ¤í…œ ìƒíƒœ
    success: bool
    error_message: str
    processing_times: Dict[str, float]


class LLMManager:
    """
    LLM ê´€ë¦¬ì (ì‹±ê¸€í†¤)
    
    Vision LLM (Qwen2.5-VL-7B)ê³¼ Text LLM (Qwen3-8B)ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    ëª¨ë¸ì„ ë¡œë“œí•œ í›„ ìœ ì§€í•˜ì—¬ ë°˜ë³µ ë¡œë”© ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤.
    """
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(LLMManager, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.vision_llm = None
            self.text_llm = None
            self.vision_loaded = False
            self.text_loaded = False
            self.config = DEFAULT_CONFIG.copy()
            LLMManager._initialized = True
    
    def load_vision_llm(self, gpu_id: int = None) -> bool:
        """Vision LLM ë¡œë“œ"""
        if self.vision_loaded and self.vision_llm is not None:
            return True
        
        try:
            from llama_cpp import Llama
            from llama_cpp.llama_chat_format import Qwen25VLChatHandler
            
            logging.info("Vision LLM ë¡œë“œ ì¤‘...")
            main_gpu = gpu_id if gpu_id is not None else self.config["MAIN_GPU"]
            
            self.vision_llm = Llama(
                model_path=self.config["VISION_MODEL_PATH"],
                chat_handler=Qwen25VLChatHandler(clip_model_path=self.config["MM_PROJ_PATH"]),
                n_gpu_layers=self.config["N_GPU_LAYERS"],
                n_ctx=self.config["N_CTX"],
                n_threads=self.config["N_THREADS"],
                n_batch=self.config["N_BATCH"],
                main_gpu=main_gpu,
                use_mmap=True,
                use_mlock=True,
                verbose=False
            )
            self.vision_loaded = True
            logging.info("Vision LLM ë¡œë“œ ì™„ë£Œ")
            return True
        except Exception as e:
            logging.error(f"Vision LLM ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_text_llm(self, gpu_id: int = None) -> bool:
        """Text LLM ë¡œë“œ"""
        if self.text_loaded and self.text_llm is not None:
            return True
        
        try:
            from llama_cpp import Llama
            
            logging.info("Text LLM ë¡œë“œ ì¤‘...")
            
            if not os.path.exists(self.config["TEXT_MODEL_PATH"]):
                logging.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config['TEXT_MODEL_PATH']}")
                return False
            
            main_gpu = gpu_id if gpu_id is not None else self.config["MAIN_GPU"]
            
            self.text_llm = Llama(
                model_path=self.config["TEXT_MODEL_PATH"],
                n_gpu_layers=self.config["N_GPU_LAYERS"],
                n_ctx=self.config["N_CTX"],
                n_threads=self.config["N_THREADS"],
                n_batch=self.config["N_BATCH"],
                main_gpu=main_gpu,
                use_mmap=True,
                use_mlock=True,
                chat_format="chatml",
                verbose=False
            )
            self.text_loaded = True
            logging.info("Text LLM ë¡œë“œ ì™„ë£Œ")
            return True
        except Exception as e:
            logging.error(f"Text LLM ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_all_models(self, gpu_id: int = None) -> bool:
        """ëª¨ë“  ëª¨ë¸ ë¡œë“œ"""
        vision_success = self.load_vision_llm(gpu_id)
        text_success = self.load_text_llm(gpu_id)
        return vision_success and text_success
    
    def unload_all_models(self):
        """ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ"""
        if self.vision_llm:
            del self.vision_llm
            self.vision_llm = None
            self.vision_loaded = False
        if self.text_llm:
            del self.text_llm
            self.text_llm = None
            self.text_loaded = False
        gc.collect()


class VideoAnalysisAgent:
    """
    ì˜ìƒ ë¶„ì„ ì—ì´ì „íŠ¸
    
    VLMìœ¼ë¡œ ì˜ìƒ ë¶„ì„ + ìƒí™© ë¶„ë¥˜ + ì‹¬ê°ë„ íŒë‹¨
    """
    
    def __init__(self, llm_manager: LLMManager = None):
        self.llm_manager = llm_manager or LLMManager()
    
    def analyze_video_and_classify(self, video_path: str) -> Dict:
        """ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„"""
        print(f"\n[VIDEO ANALYSIS AGENT] ì˜ìƒ ë¶„ì„ ì‹œì‘: {video_path}")
        
        try:
            timestamp = datetime.now().isoformat()
            frames = self._extract_frames(video_path)
            
            if not frames:
                raise ValueError("í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨")
            
            frame_analyses = []
            encoded_frames = []
            context_history = ""
            
            for i, frame in enumerate(frames):
                print(f"  [FRAME {i+1}] ë¶„ì„ ì¤‘...", end=" ")
                encoded_frame = self._encode_frame(frame)
                encoded_frames.append(encoded_frame)
                
                description = self._analyze_frame_with_vlm(encoded_frame, context_history)
                
                frame_analyses.append({
                    "timestamp": datetime.now().isoformat(),
                    "description": description,
                    "frame_data": encoded_frame
                })
                
                context_history = description
                print(f"ì™„ë£Œ: {description}")
            
            classification_result = self._classify_situation(context_history, encoded_frames)
            
            integrated_report = f"ë¶„ì„ ì™„ë£Œ: {classification_result['situation_type']} (ì‹¬ê°ë„: {classification_result['severity_level']})"
            
            print(f"[VIDEO ANALYSIS AGENT] ë¶„ì„ ì™„ë£Œ")
            print(f"[RESULT] {classification_result['situation_type']} ({classification_result['severity_level']})")
            
            return {
                "success": True,
                "video_analysis_report": integrated_report,
                "frame_analyses": frame_analyses,
                "context_history": context_history,
                "final_situation_description": context_history,
                "encoded_frames": encoded_frames,
                "timestamp": timestamp,
                "classification_report": integrated_report,
                "situation_type": classification_result["situation_type"],
                "severity_level": classification_result["severity_level"],
                "classification_reasoning": classification_result["reasoning"]
            }
            
        except Exception as e:
            print(f"[VIDEO ANALYSIS AGENT ERROR] ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "video_analysis_report": f"ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "frame_analyses": [],
                "context_history": "",
                "final_situation_description": "",
                "encoded_frames": [],
                "classification_report": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "situation_type": "ì •ìƒìƒí™©",
                "severity_level": "ê´€ì‹¬",
                "classification_reasoning": "ë¶„ì„ ì‹¤íŒ¨"
            }
    
    def _extract_frames(self, video_path: str, n_frames: int = 3) -> List[np.ndarray]:
        """ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ"""
        if not os.path.exists(video_path):
            return []
        
        frames = []
        cap = cv2.VideoCapture(video_path)
        
        try:
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            for i in range(n_frames):
                current_frame = int(i * fps)
                cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame)
                
                ret, frame = cap.read()
                if ret:
                    frames.append(frame)
        finally:
            cap.release()
        
        return frames
    
    def _encode_frame(self, frame: np.ndarray) -> str:
        """í”„ë ˆì„ì„ base64ë¡œ ì¸ì½”ë”©"""
        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        return base64.b64encode(buffer).decode('utf-8')
    
    def _analyze_frame_with_vlm(self, encoded_frame: str, context_history: str) -> str:
        """VLMìœ¼ë¡œ í”„ë ˆì„ ë¶„ì„"""
        if not self.llm_manager or not self.llm_manager.vision_llm:
            return "VLM ì—†ìŒ"
        
        system_prompt = f"""ë‹¹ì‹ ì€ CCTV ë³´ì•ˆ ì˜ìƒì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ê´€ì°°í•˜ê³  í˜„ì¬ ìƒí™©ì„ ì„¤ëª…í•˜ì„¸ìš”.

íŠ¹íˆ ë‹¤ìŒ ìœ„í—˜ ìƒí™©ë“¤ì„ ì£¼ì˜ê¹Šê²Œ ì°¾ì•„ë³´ì„¸ìš”:
- í™”ì¬: ë¶ˆê½ƒ, ì—°ê¸°, í™”ì¬ ì§•í›„
- í­ë ¥: ì‚¬ëŒë“¤ì´ ì‹¸ìš°ê±°ë‚˜ ë•Œë¦¬ëŠ” í–‰ë™, ê³µê²©ì  ìì„¸
- ì“°ëŸ¬ì§: ì‚¬ëŒì´ ì“°ëŸ¬ì ¸ ìˆê±°ë‚˜ ì˜ì‹ì„ ìƒì€ ëª¨ìŠµ

{f"ì´ì „ ìƒí™©: {context_history}" if context_history else ""}

50ì ì´ë‚´ë¡œ ì‹¤ì œ ê´€ì°°ëœ ìƒí™©ì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": [
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_frame}"}}
            ]}
        ]

        response = self.llm_manager.vision_llm.create_chat_completion(
            messages=messages,
            temperature=0.2,
            max_tokens=80
        )

        return response['choices'][0]['message']['content'].strip()
    
    def _classify_situation(self, situation_description: str, encoded_frames: List[str]) -> Dict:
        """ìƒí™© ë¶„ë¥˜ ë° ì‹¬ê°ë„ ê²°ì •"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ ê²€ì‚¬
        situation_lower = situation_description.lower()
        
        fall_keywords = ['ì“°ëŸ¬ì§', 'ì“°ëŸ¬ì ¸', 'ì“°ëŸ¬ì§„', 'ì“°ëŸ¬ì§„ë‹¤', 'ì“°ëŸ¬ì¡Œ']
        fire_keywords = ['í™”ì¬', 'ë¶ˆ', 'ì—°ê¸°', 'íƒ€ê³ ', 'íƒ€ëŠ”', 'ë¶ˆê½ƒ', 'í™”ì—¼']
        assault_keywords = ['í­í–‰', 'ë•Œë¦¬ê¸°', 'ì‹¸ì›€', 'í­ë ¥', 'ê³µê²©', 'ë•Œë¦¬ê³ ', 'ë•Œë ¤']
        
        detected_situation_type = None
        
        if any(kw in situation_lower for kw in fall_keywords):
            detected_situation_type = "ì“°ëŸ¬ì§"
        elif any(kw in situation_lower for kw in fire_keywords):
            detected_situation_type = "í™”ì¬"
        elif any(kw in situation_lower for kw in assault_keywords):
            detected_situation_type = "í­í–‰"
        
        if detected_situation_type:
            severity_map = {"í™”ì¬": "ê¸´ê¸‰", "í­í–‰": "ê²½ê³„", "ì“°ëŸ¬ì§": "ê²½ê³„", "ì •ìƒìƒí™©": "ê´€ì‹¬"}
            return {
                "situation_type": detected_situation_type,
                "severity_level": severity_map.get(detected_situation_type, "ê´€ì‹¬"),
                "reasoning": f"í‚¤ì›Œë“œ ê°ì§€: {situation_description}"
            }
        
        return {
            "situation_type": "ì •ìƒìƒí™©",
            "severity_level": "ê´€ì‹¬",
            "reasoning": "ì´ìƒ ìƒí™© ë¯¸íƒì§€"
        }


class PlannerAgent:
    """
    ê³„íšì ì—ì´ì „íŠ¸
    
    ìƒí™©ì— ë§ëŠ” ëŒ€ì‘ ê³„íš ìˆ˜ë¦½
    """
    
    def __init__(self, llm_manager: LLMManager = None):
        self.llm_manager = llm_manager or LLMManager()
    
    def create_plan(self, situation_type: str, severity_level: str, 
                    situation_description: str, feedback: str = "") -> Dict:
        """ëŒ€ì‘ ê³„íš ìˆ˜ë¦½"""
        print(f"\n[PLANNER] ê³„íš ìˆ˜ë¦½ ì‹œì‘")
        print(f"[INPUT] ìƒí™©: {situation_type}, ì‹¬ê°ë„: {severity_level}")
        
        try:
            # LLMìœ¼ë¡œ ì•¡ì…˜ ì„ íƒ ë˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í´ë°±
            if self.llm_manager and self.llm_manager.text_llm:
                actions = self._llm_select_actions(
                    situation_type, severity_level, situation_description, feedback
                )
            else:
                actions = self._create_scenario_actions(situation_type, severity_level)
            
            # ë³´ê³ ì„œ ìƒì„±
            main_actions = [a['description'] for a in actions[:3]]
            report = f"ê°ë…ìë‹˜, {situation_type} ìƒí™©(ì‹¬ê°ë„: {severity_level})ì— ëŒ€í•´ {len(actions)}ê°œ ì•¡ì…˜ ê³„íš: {', '.join(main_actions)}"
            
            plan = {
                "situation_type": situation_type,
                "severity_level": severity_level,
                "situation_description": situation_description,
                "actions": actions,
                "timestamp": datetime.now().isoformat()
            }
            
            print(f"[PLANNER] {len(actions)}ê°œ ì•¡ì…˜ ê³„íš ì™„ë£Œ")
            
            return {"success": True, "report": report, "plan": plan}
            
        except Exception as e:
            print(f"[PLANNER ERROR] ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "report": f"ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}",
                "plan": {"situation_type": situation_type, "severity_level": severity_level, 
                         "situation_description": situation_description, "actions": [], 
                         "timestamp": datetime.now().isoformat()}
            }
    
    def _llm_select_actions(self, situation_type: str, severity_level: str,
                            situation_description: str, feedback: str = "") -> List[Dict]:
        """LLMìœ¼ë¡œ ì•¡ì…˜ ì„ íƒ (Tool Calling ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í´ë°± ì‚¬ìš© (ì•ˆì •ì„±)
        return self._create_scenario_actions(situation_type, severity_level)
    
    def _create_scenario_actions(self, situation_type: str, severity_level: str) -> List[Dict]:
        """ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¸°ë³¸ ì•¡ì…˜"""
        action_names = SCENARIO_ACTIONS.get(situation_type, {}).get(
            severity_level, ["continue_monitoring", "log_normal_incident"]
        )
        
        actions = []
        for name in action_names:
            if name in AVAILABLE_ACTIONS:
                actions.append({
                    "name": name,
                    "params": AVAILABLE_ACTIONS[name]["params_template"].copy(),
                    "description": AVAILABLE_ACTIONS[name]["description"]
                })
        
        return actions


class SupervisorAgent:
    """
    ê°ë…ì ì—ì´ì „íŠ¸
    
    ê³„íš ê²€í†  ë° ìŠ¹ì¸/ê±°ë¶€
    """
    
    def __init__(self, llm_manager: LLMManager = None):
        self.llm_manager = llm_manager or LLMManager()
    
    def instruct_planner(self, situation_type: str, severity_level: str, 
                         situation_description: str) -> Dict:
        """Plannerì—ê²Œ ê³„íš ìˆ˜ë¦½ ì§€ì‹œ"""
        print(f"\n[SUPERVISOR] Plannerì—ê²Œ ê³„íš ìˆ˜ë¦½ ì§€ì‹œ")
        print(f"[SUPERVISOR] ìƒí™©: {situation_type}, ì‹¬ê°ë„: {severity_level}")
        return {"success": True}
    
    def review_plan(self, planner_report: str, plan: Dict, 
                    situation_type: str = "", severity_level: str = "") -> Dict:
        """ê³„íš ê²€í†  ë° ìŠ¹ì¸/ê±°ë¶€"""
        print(f"\n[SUPERVISOR] ê³„íš ê²€í†  ì¤‘...")
        
        try:
            actions = plan.get("actions", [])
            action_count = len(actions)
            
            # ê¸°ì¤€ 1: ìµœì†Œ 1ê°œ ì•¡ì…˜
            criterion1_ok = action_count >= 1
            
            # ê¸°ì¤€ 2: ìƒí™© ì í•©ì„±
            situation_keywords = {
                "í™”ì¬": ["í™”ì¬", "fire", "ì†Œë°©"],
                "í­í–‰": ["í­í–‰", "assault", "í­ë ¥", "police", "ê²½ì°°", "security", "ì¦ê±°"],
                "ì“°ëŸ¬ì§": ["ì“°ëŸ¬", "fall", "ë‚™ìƒ", "ì‘ê¸‰", "ì˜ë£Œ", "medical", "êµ¬ê¸‰"]
            }
            criterion2_ok = True
            if situation_type in situation_keywords:
                keywords = situation_keywords[situation_type]
                criterion2_ok = any(
                    any(kw.lower() in a.get('name', '').lower() or kw.lower() in a.get('description', '').lower() 
                        for kw in keywords)
                    for a in actions
                )
            
            # ê¸°ì¤€ 3: ì‹¬ê°ë„ë³„ ì ì • ì•¡ì…˜ ìˆ˜
            if situation_type == "ì •ìƒìƒí™©" and severity_level == "ê´€ì‹¬":
                min_actions, max_actions = 2, 2
            else:
                severity_requirements = {"ê¸´ê¸‰": (4, 5), "ê²½ê³„": (3, 3), "ê´€ì‹¬": (1, 1)}
                min_actions, max_actions = severity_requirements.get(severity_level, (1, 1))
            
            criterion3_ok = min_actions <= action_count <= max_actions
            
            all_criteria_met = criterion1_ok and criterion2_ok and criterion3_ok
            
            if not all_criteria_met:
                feedback_parts = []
                if not criterion1_ok:
                    feedback_parts.append("ì•¡ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                if not criterion2_ok:
                    feedback_parts.append(f"ìƒí™©({situation_type})ì— ë§ì§€ ì•ŠëŠ” ì•¡ì…˜")
                if not criterion3_ok:
                    feedback_parts.append(f"{min_actions}-{max_actions}ê°œ í•„ìš”, í˜„ì¬ {action_count}ê°œ")
                
                return {
                    "success": True,
                    "approved": False,
                    "review": f"ê¸°ì¤€ ë¯¸ë‹¬: {', '.join(feedback_parts)}",
                    "feedback": '; '.join(feedback_parts)
                }
            
            return {"success": True, "approved": True, "review": "ê·œì¹™ ê¸°ë°˜ ìŠ¹ì¸", "feedback": ""}
            
        except Exception as e:
            print(f"[SUPERVISOR ERROR] ê²€í†  ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "approved": True, "review": f"ê²€í†  ì‹¤íŒ¨: {e}", "feedback": ""}


class ActorAgent:
    """
    ì‹¤í–‰ ì—ì´ì „íŠ¸
    
    ê³„íšëœ ì•¡ì…˜ ì‹¤í–‰
    """
    
    def __init__(self, llm_manager: LLMManager = None):
        self.llm_manager = llm_manager or LLMManager()
        self._current_plan_context = None
        
        # Tool registry
        self.tools = {
            "activate_fire_alarm": lambda p: f"ğŸ”¥ í™”ì¬ ê²½ë³´ ë°œë ¹: {p.get('message', 'í™”ì¬ë°œìƒëŒ€í”¼í•˜ì‹­ì‹œì˜¤')}",
            "call_fire_department": lambda p: "ğŸ“ 119 ì†Œë°©ì„œ ìë™ ì‹ ê³  ì™„ë£Œ",
            "dispatch_fire_response_team": lambda p: f"ğŸ‘¨â€ğŸš’ ì²­ì›ê²½ì°° {p.get('team_size', 2)}ëª… í™”ì¬ ëŒ€ì‘ ì¶œë™",
            "activate_fire_systems": lambda p: f"ğŸ’§ ì†Œë°© ì‹œìŠ¤í…œ ì‘ë™: ìŠ¤í”„ë§í´ëŸ¬={p.get('sprinkler', 'on')}",
            "log_fire_incident": lambda p: f"ğŸ“ í™”ì¬ ì‚¬ê±´ ë¡œê·¸ ì €ì¥ ì™„ë£Œ",
            "activate_assault_warning": lambda p: "âš ï¸ í­í–‰ ê²½ê³  ë°©ì†¡ ì™„ë£Œ",
            "call_police": lambda p: "ğŸ“ 112 ê²½ì°°ì„œ ìë™ ì‹ ê³  ì™„ë£Œ",
            "dispatch_security_team": lambda p: f"ğŸ‘® ì²­ì›ê²½ì°° {p.get('team_size', 2)}ëª… ì¶œë™",
            "secure_evidence": lambda p: "ğŸ“¹ ì¦ê±° ì˜ìƒ í™•ë³´ ì™„ë£Œ",
            "log_assault_incident": lambda p: "ğŸ“ í­í–‰ ì‚¬ê±´ ë¡œê·¸ ì €ì¥ ì™„ë£Œ",
            "activate_medical_assistance": lambda p: "ğŸ¥ ì˜ë£Œ ì§€ì› ì•ˆë‚´ ë°©ì†¡ ì™„ë£Œ",
            "call_ambulance": lambda p: "ğŸš‘ 119 êµ¬ê¸‰ëŒ€ ìë™ ì‹ ê³  ì™„ë£Œ",
            "dispatch_medical_team": lambda p: f"ğŸ‘¨â€âš•ï¸ ì²­ì›ê²½ì°° {p.get('team_size', 2)}ëª… ì˜ë£Œ ëŒ€ì‘ ì¶œë™",
            "guide_emergency_access": lambda p: "ğŸ›£ï¸ êµ¬ê¸‰ì°¨ ì§„ì… ê²½ë¡œ í™•ë³´ ì™„ë£Œ",
            "log_medical_incident": lambda p: "ğŸ“ ì˜ë£Œ ì‚¬ê±´ ë¡œê·¸ ì €ì¥ ì™„ë£Œ",
            "continue_monitoring": lambda p: "ğŸ‘ï¸ ì •ìƒ ëª¨ë‹ˆí„°ë§ ê³„ì†",
            "log_normal_incident": lambda p: "ğŸ“ ì •ìƒ ìƒí™© ë¡œê·¸ ì €ì¥ ì™„ë£Œ",
        }
    
    def execute_plan(self, plan: Dict, instruction: str = "", timestamp: str = None) -> Dict:
        """ê³„íš ì‹¤í–‰"""
        print(f"\n[ACTOR] ê³„íš ì‹¤í–‰ ì‹œì‘")
        
        actions = plan.get("actions", [])
        if not actions:
            return {"success": False, "error": "ì‹¤í–‰í•  ì•¡ì…˜ ì—†ìŒ", "execution_results": []}
        
        self._current_plan_context = {
            "situation_type": plan.get("situation_type", ""),
            "severity_level": plan.get("severity_level", ""),
            "situation_description": plan.get("situation_description", ""),
            "timestamp": timestamp,
            "execution_history": []
        }
        
        try:
            # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì •ë ¬
            ordered_actions = sorted(actions, key=lambda a: ACTION_PRIORITY.get(a.get("name", ""), 50))
            
            execution_results = []
            for i, action in enumerate(ordered_actions):
                action_name = action.get("name", "")
                action_params = action.get("params", {})
                action_desc = action.get("description", "")
                
                print(f"[ACTION {i+1}/{len(ordered_actions)}] {action_name}")
                
                if action_name in self.tools:
                    result = self.tools[action_name](action_params)
                else:
                    result = f"[UNKNOWN] {action_name}"
                
                execution_results.append({
                    "action_index": i + 1,
                    "action_name": action_name,
                    "action_description": action_desc,
                    "params": action_params,
                    "result": result,
                    "timestamp": datetime.now().isoformat(),
                    "success": True
                })
                
                print(f"[RESULT] {result}")
            
            print(f"[ACTOR] ëª¨ë“  ì•¡ì…˜ ì‹¤í–‰ ì™„ë£Œ ({len(execution_results)}ê°œ)")
            
            return {"success": True, "execution_results": execution_results}
            
        except Exception as e:
            print(f"[ACTOR ERROR] ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "execution_results": []}



