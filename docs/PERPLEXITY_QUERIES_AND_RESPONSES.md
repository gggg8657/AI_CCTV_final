# Perplexity ê²€ìƒ‰ ì¿¼ë¦¬ì™€ ì‘ë‹µ êµ¬ë¶„

**ê²€ìƒ‰ ì¼ì‹œ**: 2026-01-21  
**ëª©ì **: Vision-Agents í†µí•©ì„ ìœ„í•œ ê¸°ìˆ  ì¡°ì‚¬

---

## ê²€ìƒ‰ 1: Vision-Agents Security Camera Example ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ

### ğŸ“¤ Cursorê°€ Perplexityì—ê²Œ ë³´ë‚¸ ì¿¼ë¦¬
```
Vision-Agents Security Camera Example event system architecture pattern implementation 2024 2025
```

### ğŸ“¥ Perplexity ì‘ë‹µ (ì›ë¬¸ ê·¸ëŒ€ë¡œ)

#### ì‘ë‹µ 1: Chapter 13: Pattern 5: Vision-Based Agents - The Agentic Web
**URL**: https://www.theagenticweb.dev/blueprint/pattern-vision-agents

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Vision agentsëŠ” ì—ì´ì „íŠ¸ì—ê²Œ "ëˆˆ"ì„ ì œê³µ
- E-commerce, ë³´ì•ˆ ì‹œìŠ¤í…œ, í—¬ìŠ¤ì¼€ì–´, ì¸ë²¤í† ë¦¬ ê´€ë¦¬ ë“±ì— í™œìš©
- ì•„í‚¤í…ì²˜ íŒ¨í„´: INPUT LAYER â†’ VISION PROCESSING â†’ AGENT REASONING â†’ ACTION
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì— ì í•©
- ê³ ì£¼íŒŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ë‚˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì—ëŠ” ë¹„ìš©/ì§€ì—° ë¬¸ì œ

**Security Vision Service ì˜ˆì‹œ ì½”ë“œ**:
```typescript
export class SecurityVisionService {
  private sceneHistory: Map<string, string> = new Map();
  
  async monitorSecurityFeed(
    cameraId: string,
    imageBuffer: Buffer
  ): Promise<SecurityAlert | null> {
    // ì‚¬ëŒ ê°ì§€
    const peopleDetection = await vision.detect(imageBuffer, 'person');
    const peopleCount = peopleDetection.objects?.length || 0;
    
    if (peopleCount > 0) {
      // ìƒì„¸ ë¶„ì„
      const analysis = await vision.query(
        imageBuffer,
        `Describe the ${peopleCount} person(s) in this image: What are they doing? Are they wearing any identifiable clothing or carrying anything?`
      );
      
      // ë³´ì•ˆ ì—ì´ì „íŠ¸ì—ê²Œ ì „ë‹¬
      const alert = await securityAgent.generate(`SECURITY ALERT - Camera ${cameraId}...`);
      
      if (alert.text.includes('HIGH') || alert.text.includes('CRITICAL')) {
        return {
          cameraId,
          threatLevel: alert.text.includes('CRITICAL') ? 'CRITICAL' : 'HIGH',
          peopleCount,
          description: analysis.answer,
          recommendation: alert.text,
          timestamp: new Date(),
        };
      }
    }
    return null;
  }
}
```

#### ì‘ë‹µ 2: A Vision-Based Intelligent Architecture for Security System
**URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC9129940/

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Vision ê¸°ë°˜ ë³´ì•ˆ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
- ì–¼êµ´ ì¸ì‹ ë° ì„¼ì„œ í†µí•©
- Raspberry Pi 3 ê¸°ë°˜ êµ¬í˜„
- SVM + HOGë¥¼ ì‚¬ìš©í•œ ì–¼êµ´ ì¸ì‹ (99.9% ì •í™•ë„)
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° í´ë¼ìš°ë“œ ìŠ¤íŠ¸ë¦¬ë°
- REST ë° WebSocket í”„ë¡œí† ì½œ ì‚¬ìš©

#### ì‘ë‹µ 3: Real-Time Event Processing In Security Camera Systems
**URL**: https://www.espjeta.org/Volume2-Issue1/JETA-V2I1P113.pdf

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- ë³´ì•ˆ ì¹´ë©”ë¼ ì‹œìŠ¤í…œì˜ ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì²˜ë¦¬
- Auto-Sharding ë° In-Memory Caching ì ‘ê·¼ë²•
- ì´ë²¤íŠ¸ ì²˜ë¦¬ ë‹¨ê³„:
  1. Event Detection and Initial Upload
  2. On-Device Event Classification
  3. Further refinement and metadata generation
- Stateless ì•„í‚¤í…ì²˜ì˜ ì„±ëŠ¥ ë³‘ëª© ë¬¸ì œ
- Auto-Shardingìœ¼ë¡œ ì´ë²¤íŠ¸ ë¼ìš°íŒ… ìµœì í™”
- In-Memory Cachingìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ ê°ì†Œ

**ì´ë²¤íŠ¸ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°**:
```
Event Reception and Routing
  â†’ Camera Service Task (Sharding-aware)
  â†’ In-Memory Cache Check
  â†’ Database Update (if needed)
  â†’ Event Processing
```

#### ì‘ë‹µ 4: Computer Vision Based Smart Security System
**URL**: https://myresearchspace.uws.ac.uk/ws/portalfiles/portal/54673092/2024_09_12_Nisbet_et_al_Computer_accepted.pdf

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Edge Computing ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë³´ì•ˆ ì‹œìŠ¤í…œ
- Explainable AI (XAI) í†µí•©
- ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ê°ì‹œ
- ì–¼êµ´ ê°ì§€, ìº¡ì²˜, ì‹ë³„ íŒŒì´í”„ë¼ì¸
- Edge ë””ë°”ì´ìŠ¤ì— í†µí•©ëœ ì• í”Œë¦¬ì¼€ì´ì…˜

#### ì‘ë‹µ 5: Scalable Architectures for Video Surveillance Services
**URL**: https://codex.yubetsu.com/article/e29295cc95774dda8bf1a59dec9f3ea6

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Event-Driven Architecture (EDA) ê¸°ë°˜ ë¹„ë””ì˜¤ ê°ì‹œ ì„œë¹„ìŠ¤
- Pub/Sub ëª¨ë¸ í™œìš©
- Cloud Computing ë° Edge Computing í†µí•©
- IoT ë””ë°”ì´ìŠ¤ì™€ì˜ í†µí•©
- ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê°ì§€ ë° ì‘ë‹µ
- ë°ì´í„° ë³´ì•ˆ ë° í”„ë¼ì´ë²„ì‹œ ê³ ë ¤ì‚¬í•­

---

## ê²€ìƒ‰ 2: YOLO v12 nano íŒ¨í‚¤ì§€ ê°ì§€ êµ¬í˜„

### ğŸ“¤ Cursorê°€ Perplexityì—ê²Œ ë³´ë‚¸ ì¿¼ë¦¬
```
YOLO v12 nano ultralytics package detection object tracking implementation python 2025
```

### ğŸ“¥ Perplexity ì‘ë‹µ (ì›ë¬¸ ê·¸ëŒ€ë¡œ)

#### ì‘ë‹µ 1: Object Detection - Ultralytics YOLO Docs
**URL**: https://docs.ultralytics.com/tasks/detect/

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- YOLO26n: 640px, mAP 40.9, Speed CPU ONNX 38.9ms, Speed T4 TensorRT 1.7ms
- ê°ì²´ ê°ì§€ ê¸°ë³¸ ì‚¬ìš©ë²•:
```python
from ultralytics import YOLO

# ëª¨ë¸ ë¡œë“œ
model = YOLO("yolo26n.pt")

# ì˜ˆì¸¡
results = model("path/to/image.jpg")

# ê²°ê³¼ ì ‘ê·¼
for result in results:
    xywh = result.boxes.xywh  # center-x, center-y, width, height
    xyxy = result.boxes.xyxy  # top-left-x, top-left-y, bottom-right-x, bottom-right-y
    names = [result.names[cls.item()] for cls in result.boxes.cls.int()]
    confs = result.boxes.conf
```

#### ì‘ë‹µ 2: Ultralytics YOLO Docs: Home
**URL**: https://docs.ultralytics.com

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- YOLO26: ìµœì‹  ë²„ì „, NMS-free inference, Edge ìµœì í™”
- YOLO11: 2024ë…„ 9ì›” ì¶œì‹œ, ì•ˆì •ì 
- YOLO12: 2025ë…„ ì´ˆ ì¶œì‹œ, Attention-centric ì•„í‚¤í…ì²˜
- YOLO11n: 640px, mAP 39.5, Speed CPU ONNX 56.1ms, Speed T4 TensorRT 1.5ms
- ê°ì²´ ì¶”ì  ì§€ì›: `yolo track` ëª…ë ¹ì–´

#### ì‘ë‹µ 3: Ultralytics YOLO GitHub
**URL**: https://github.com/ultralytics/ultralytics

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- YOLO11n: 640px, mAP 39.5, params 2.6M, FLOPs 6.5B
- CLI ì‚¬ìš©ë²•:
```bash
yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'
```
- Python ì‚¬ìš©ë²•:
```python
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
results = model("path/to/image.jpg")
results[0].show()
```

#### ì‘ë‹µ 4: How to Use YOLO12 for Object Detection
**URL**: https://www.youtube.com/watch?v=mcqTxD-FD5M

**Perplexityê°€ ì°¾ì€ ë‚´ìš©** (YouTube ë¹„ë””ì˜¤ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸):
- YOLO12ëŠ” Ultralytics íŒ¨í‚¤ì§€ë¡œ ì‚¬ìš© ê°€ëŠ¥
- YOLO11ì´ YOLO12ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ (Ultralytics ê¶Œì¥)
- YOLO12 Nano ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ
- ì¶”ë¡  ì†ë„: ì•½ 17ms (ë¹„ë””ì˜¤ ì²˜ë¦¬)

#### ì‘ë‹µ 5: How to Build Interactive Object Tracking
**URL**: https://www.youtube.com/watch?v=leOPZhE0ckg

**Perplexityê°€ ì°¾ì€ ë‚´ìš©** (YouTube ë¹„ë””ì˜¤ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸):
- ì‹¤ì‹œê°„ ê°ì²´ ì¶”ì  êµ¬í˜„
- í´ë¦­ìœ¼ë¡œ ê°ì²´ í¬ë¡­ ë° í‘œì‹œ
- ì¶”ì  íŒŒì´í”„ë¼ì¸:
```python
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
results = model.track(source="path/to/video.mp4")
```

---

## ê²€ìƒ‰ 3: Python ì´ë²¤íŠ¸ ë²„ìŠ¤ Pub/Sub íŒ¨í„´ êµ¬í˜„

### ğŸ“¤ Cursorê°€ Perplexityì—ê²Œ ë³´ë‚¸ ì¿¼ë¦¬
```
Python event bus pub sub pattern implementation async threading best practices 2024
```

### ğŸ“¥ Perplexity ì‘ë‹µ (ì›ë¬¸ ê·¸ëŒ€ë¡œ)

#### ì‘ë‹µ 1: Pythonã¨ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ï¼šasyncio + Pub/Subãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆå®Ÿè·µ
**URL**: https://qiita.com/CRUD5th/items/d7d8a39e3af150598e89

**Perplexityê°€ ì°¾ì€ ë‚´ìš©** (ì¼ë³¸ì–´ ë¬¸ì„œ):
- asyncioì™€ Pub/Sub ëª¨ë¸ ì¡°í•©
- ìµœì†Œ Pub/Sub ë²„ìŠ¤ êµ¬í˜„:
```python
import asyncio
from collections import defaultdict

class EventBus:
    def __init__(self):
        self._subscribers = defaultdict(list)
    
    def subscribe(self, event_name, callback):
        self._subscribers[event_name].append(callback)
    
    async def publish(self, event_name, data):
        for callback in self._subscribers[event_name]:
            await callback(data)
```

- asyncio.Queueë¥¼ ì‚¬ìš©í•œ ì´ë²¤íŠ¸ ë£¨í”„:
```python
class AsyncEventQueue:
    def __init__(self):
        self.queue = asyncio.Queue()
        self.subscribers = defaultdict(list)
    
    def subscribe(self, event_type, handler):
        self.subscribers[event_type].append(handler)
    
    async def publish(self, event_type, payload):
        await self.queue.put((event_type, payload))
    
    async def run(self):
        while True:
            event_type, payload = await self.queue.get()
            for handler in self.subscribers[event_type]:
                await handler(payload)
```

#### ì‘ë‹µ 2: PubSub Model in Python
**URL**: https://www.geeksforgeeks.org/python/pubsub-model-in-python/

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- queue ëª¨ë“ˆì„ ì‚¬ìš©í•œ ê¸°ë³¸ Pub/Sub:
```python
import queue

class Publisher:
    def __init__(self):
        self.message_queue = queue.Queue()
        self.subscribers = []
    
    def subscribe(self, subscriber):
        self.subscribers.append(subscriber)
    
    def publish(self, message):
        self.message_queue.put(message)
        for subscriber in self.subscribers:
            subscriber.receive(message)
```

- threading ëª¨ë“ˆì„ ì‚¬ìš©í•œ Pub/Sub:
```python
import threading

class Publisher:
    def __init__(self):
        self.subscribers = {}
    
    def subscribe(self, subscriber, topic):
        if topic not in self.subscribers:
            self.subscribers[topic] = []
        self.subscribers[topic].append(subscriber)
    
    def publish(self, message, topic):
        if topic in self.subscribers:
            for subscriber in self.subscribers[topic]:
                subscriber.event.set()
                subscriber.message = message
```

#### ì‘ë‹µ 3: bubus - Production-ready python event bus library
**URL**: https://github.com/browser-use/bubus

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Pydantic ê¸°ë°˜ íƒ€ì… ì•ˆì „ ì´ë²¤íŠ¸ ë²„ìŠ¤
- Async/Sync í•¸ë“¤ëŸ¬ ì§€ì›
- ì´ë²¤íŠ¸ í¬ì›Œë”© ì§€ì›
- ì‚¬ìš© ì˜ˆì‹œ:
```python
from bubus import EventBus, BaseEvent

class UserLoginEvent(BaseEvent[str]):
    username: str
    is_admin: bool

async def handle_login(event: UserLoginEvent) -> str:
    # ì²˜ë¦¬ ë¡œì§
    pass

bus = EventBus()
bus.on(UserLoginEvent, handle_login)
await bus.dispatch(UserLoginEvent(username="user", is_admin=False))
```

- ë³‘ë ¬ í•¸ë“¤ëŸ¬ ì‹¤í–‰ ì§€ì›:
```python
bus = EventBus(parallel_handlers=True)
```

#### ì‘ë‹µ 4: Async and Sync Python Pub/Sub with Redis
**URL**: https://saktidwicahyono.name/blogs/async-and-sync-python-pubsub-with-redis/

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Redisë¥¼ ì‚¬ìš©í•œ Pub/Sub êµ¬í˜„
- Async ë²„ì „ì´ Sync ë²„ì „ë³´ë‹¤ 3.66ë°° ë¹ ë¦„
- Async ì˜ˆì‹œ:
```python
import asyncio
import redis.asyncio as redis

async def handle_notification():
    r = redis.Redis()
    pubsub = r.pubsub()
    await pubsub.subscribe(CHANNEL_NAME)
    
    while True:
        message = await pubsub.get_message()
        if message and message["type"] == "message":
            payload = json.loads(message["data"])
            await process_message(payload)
```

#### ì‘ë‹µ 5: Fast Pub-Sub python implementation: threading
**URL**: https://dev.to/mandrewcito/fast-pub-sub-python-implementation-threading-ii-1khp

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Threading ê¸°ë°˜ Pub/Sub êµ¬í˜„
- Non-blocking Publisher:
```python
class ThreadedEventChannel(EventChannel):
    def __init__(self, blocking=True):
        self.blocking = blocking
        super(ThreadedEventChannel, self).__init__()
    
    def publish(self, event, *args, **kwargs):
        threads = []
        if event in self.subscribers.keys():
            for callback in self.subscribers[event]:
                threads.append(threading.Thread(
                    target=callback,
                    args=args,
                    kwargs=kwargs
                ))
            for th in threads:
                th.start()
            if self.blocking:
                for th in threads:
                    th.join()
```

- ì„±ëŠ¥: Threadedê°€ Non-threadedë³´ë‹¤ 2ë°° ë¹ ë¦„

---

## ê²€ìƒ‰ 4: LLM Function Calling êµ¬í˜„ íŒ¨í„´

### ğŸ“¤ Cursorê°€ Perplexityì—ê²Œ ë³´ë‚¸ ì¿¼ë¦¬
```
LLM function calling implementation pattern registry system Qwen3 OpenAI 2024 2025
```

### ğŸ“¥ Perplexity ì‘ë‹µ (ì›ë¬¸ ê·¸ëŒ€ë¡œ)

#### ì‘ë‹µ 1: Function Calling - Qwen Documentation
**URL**: https://qwen.readthedocs.io/en/latest/framework/function_call.html

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Qwen-AgentëŠ” Qwen3ì˜ Function Calling í‘œì¤€ êµ¬í˜„
- OpenAI-compatible API ë˜í•‘
- Hermes-style tool use ì§€ì›
- ì¤€ë¹„ ì½”ë“œ:
```python
from qwen_agent.llm import get_chat_model

llm = get_chat_model({
    "model": "Qwen/Qwen3-8B",
    "model_server": "http://localhost:8000/v1",
    "api_key": "EMPTY",
    "generate_cfg": {
        "extra_body": {
            "chat_template_kwargs": {"enable_thinking": False}
        }
    }
})
```

- Tool Calls ì²˜ë¦¬:
```python
if tool_calls := messages[-1].get("tool_calls", None):
    for tool_call in tool_calls:
        call_id: str = tool_call["id"]
        if fn_call := tool_call.get("function"):
            fn_name: str = fn_call["name"]
            fn_args: dict = json.loads(fn_call["arguments"])
            fn_res: str = json.dumps(get_function_by_name(fn_name)(**fn_args))
            messages.append({
                "role": "tool",
                "content": fn_res,
                "tool_call_id": call_id,
            })
```

#### ì‘ë‹µ 2: Create Function-calling Agent using OpenVINO and Qwen-Agent
**URL**: https://docs.openvino.ai/2024/notebooks/llm-agent-functioncall-qwen-with-output.html

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Qwen-Agentì˜ Assistant í´ë˜ìŠ¤ ì‚¬ìš©
- Function callingì„ í†µí•œ ì—ì´ì „íŠ¸ ìƒì„±:
```python
from qwen_agent.agents import Assistant

bot = Assistant(llm=llm_cfg, function_list=tools, name="OpenVINO Agent")
```

- Function ì •ì˜ í˜•ì‹:
```python
functions = [
    {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "The city and state, e.g. San Francisco, CA",
                },
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
            },
            "required": ["location"],
        },
    }
]
```

#### ì‘ë‹µ 3: Function Calling and Tool Use | QwenLM/Qwen3
**URL**: https://deepwiki.com/QwenLM/Qwen3/3.3-function-calling-and-tool-use

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Function Calling ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ:
  - Chat Template: í•¨ìˆ˜ ì •ì˜ ë° í˜¸ì¶œ í¬ë§·íŒ…
  - Tool Parser: ëª¨ë¸ ì¶œë ¥ì—ì„œ êµ¬ì¡°í™”ëœ í˜¸ì¶œ ì¶”ì¶œ
  - Function Registry: í•¨ìˆ˜ ì´ë¦„ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¡œ ë§¤í•‘
  - Result Processor: í•¨ìˆ˜ ê²°ê³¼ë¥¼ ëŒ€í™”ì— í†µí•©

- Function Calling ì›Œí¬í”Œë¡œìš°:
  1. Initial: user ë©”ì‹œì§€ (ìì—°ì–´ ì§ˆì˜)
  2. Function Call: assistant ë©”ì‹œì§€ (function_call ë˜ëŠ” tool_calls)
  3. Function Result: function/tool ë©”ì‹œì§€ (JSON ê²°ê³¼)
  4. Final Response: assistant ë©”ì‹œì§€ (ìì—°ì–´ ì‘ë‹µ)

#### ì‘ë‹µ 4: Qwen3 GitHub - Function Calling
**URL**: https://github.com/QwenLM/Qwen3/blob/main/docs/source/framework/function_call.md

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- vLLMì„ ì‚¬ìš©í•œ Function Calling:
```bash
vllm serve Qwen/Qwen3-8B --enable-auto-tool-choice --tool-call-parser hermes --reasoning-parser deepseek_r1
```

- OpenAI API í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©:
```python
from openai import OpenAI

client = OpenAI(
    api_key="EMPTY",
    base_url="http://localhost:8000/v1",
)

response = client.chat.completions.create(
    model="Qwen/Qwen3-8B",
    messages=messages,
    tools=tools,
    temperature=0.7,
    top_p=0.8,
    max_tokens=512,
    extra_body={
        "repetition_penalty": 1.05,
        "chat_template_kwargs": {"enable_thinking": False}
    },
)
```

#### ì‘ë‹µ 5: QwenLM/Qwen3 GitHub
**URL**: https://github.com/QwenLM/Qwen3

**Perplexityê°€ ì°¾ì€ ë‚´ìš©**:
- Qwen3 ì£¼ìš” íŠ¹ì§•:
  - Agent capabilities ì „ë¬¸ì„±
  - 100+ ì–¸ì–´ ì§€ì›
  - Thinking mode ë° No-thinking mode ì§€ì›
- Transformers í”„ë ˆì„ì›Œí¬ ì‚¬ìš©:
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-30B-A3B-Instruct-2507"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
```

---

*ì´ ë¬¸ì„œëŠ” Cursorê°€ Perplexityì—ê²Œ ë³´ë‚¸ ì¿¼ë¦¬ì™€ Perplexityì˜ ì‘ë‹µì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ê¸°ë¡í•œ ê²ƒì…ë‹ˆë‹¤.*
