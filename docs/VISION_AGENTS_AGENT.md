***

# Vision-Agents Technical Report

## PART 2: Agent í´ë˜ìŠ¤ ìƒì„¸ ë¶„ì„

### 2.1 Agent í´ë˜ìŠ¤ ê°œìš”

**íŒŒì¼**: `agents-core/vision_agents/core/agents/agents.py`  
**í¬ê¸°**: 1428 lines (1203 LOC)  
**ë©”ì¸ í´ë˜ìŠ¤**: `Agent`

```python
class Agent:
    """
    AgentëŠ” Vision-Agentsì˜ í•µì‹¬ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    ì—­í• :
    â”œâ”€ ëª¨ë“  í”ŒëŸ¬ê·¸ì¸ í†µí•© (LLM, STT, TTS, Processors)
    â”œâ”€ ì´ë²¤íŠ¸ ê´€ë¦¬ (Event Hub)
    â”œâ”€ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬
    â”œâ”€ í†µí™” ìƒëª… ì£¼ê¸° ê´€ë¦¬
    â””â”€ ìƒíƒœ ìœ ì§€ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    
    ìƒëª… ì£¼ê¸°:
    1. __init__()        - ì´ˆê¸°í™”
    2. join(call)        - í†µí™” ì°¸ì—¬
    3. finish()          - í†µí™” ì¢…ë£Œ ëŒ€ê¸°
    4. close()           - ì •ë¦¬
    """
```

***

### 2.2 Agent ì´ˆê¸°í™” (__init__)

```python
def __init__(
    self,
    # ===== í•„ìˆ˜ íŒŒë¼ë¯¸í„° =====
    edge: "StreamEdge",                     # ì—£ì§€ ë„¤íŠ¸ì›Œí¬ (GetStream)
    llm: LLM | AudioLLM | VideoLLM,        # ì–¸ì–´ ëª¨ë¸
    agent_user: User,                      # ì—ì´ì „íŠ¸ ìœ ì € ì •ë³´
    
    # ===== ì„ íƒ íŒŒë¼ë¯¸í„° =====
    instructions: str = "Keep replies short",  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    
    # ìŒì„± ì²˜ë¦¬ (STT/TTS ëª¨ë“œì—ì„œë§Œ)
    stt: Optional[STT] = None,             # ìŒì„±â†’í…ìŠ¤íŠ¸
    tts: Optional[TTS] = None,             # í…ìŠ¤íŠ¸â†’ìŒì„±
    turn_detection: Optional[TurnDetector] = None,  # ë°œí™” ê°ì§€
    
    # í™•ì¥ ê¸°ëŠ¥
    processors: Optional[List[Processor]] = None,   # ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ì²˜ë¦¬
    mcp_servers: Optional[List[MCPBaseServer]] = None,  # ì™¸ë¶€ ë„êµ¬
    
    # ê´€ì°°ì„±
    options: Optional[AgentOptions] = None,  # ì„¤ì •
    tracer: Tracer = trace.get_tracer("agents"),  # OpenTelemetry
    profiler: Optional[Profiler] = None,  # ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
):
```

#### 2.2.1 ì´ˆê¸°í™” ë‹¨ê³„ (Step-by-step)

**Step 1: ID ë° ê¸°ë³¸ ì •ë³´ ì„¤ì •**
```python
# 1. ì—ì´ì „íŠ¸ ê³ ìœ  ID ìƒì„± (UUID4)
self._id = str(uuid4())  # ì˜ˆ: "f47ac10b-58cc-4372-a567-0e02b2c3d479"

# 2. ì‚¬ìš©ì ì •ë³´ ì„¤ì •
self.agent_user = agent_user
if not self.agent_user.id:
    self.agent_user.id = f"agent-{uuid4()}"

# 3. ìƒíƒœ í”Œë˜ê·¸
self._pending_turn: Optional[LLMTurn] = None      # í˜„ì¬ LLM í„´
self.call: Optional[Call] = None                  # í˜„ì¬ í†µí™”
self._closed = False                              # ì¢…ë£Œ ìƒíƒœ
```

**Step 2: ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”**
```python
# ì´ë²¤íŠ¸ ë§¤ë‹ˆì € ìƒì„±
self.events = EventManager()  # ì¤‘ì•™ ì´ë²¤íŠ¸ í—ˆë¸Œ

# ëª¨ë“  í”ŒëŸ¬ê·¸ì¸ì˜ ì´ë²¤íŠ¸ ë“±ë¡
self.events.register_events_from_module(getstream.models, "call.")
self.events.register_events_from_module(events)          # Agent Events
self.events.register_events_from_module(sfu_events)      # SFU Events
self.events.register_events_from_module(llm_events)      # LLM Events

# í”ŒëŸ¬ê·¸ì¸ ì´ë²¤íŠ¸ ë³‘í•© (Merge)
for plugin in [stt, tts, turn_detection, llm, edge, profiler]:
    if plugin and hasattr(plugin, "events"):
        self.events.merge(plugin.events)  # í”ŒëŸ¬ê·¸ì¸ ì´ë²¤íŠ¸ ì¶”ê°€
```

**Step 3: í”ŒëŸ¬ê·¸ì¸ í• ë‹¹**
```python
self.llm = llm                           # LLM ëª¨ë¸
self.stt = stt                           # ìŒì„± ì¸ì‹
self.tts = tts                           # ìŒì„± í•©ì„±
self.turn_detection = turn_detection     # ë°œí™” ê°ì§€
self.processors: list[Processor] = processors or []  # í”„ë¡œì„¸ì„œ
self.mcp_servers = mcp_servers or []     # ì™¸ë¶€ ë„êµ¬
self.edge = edge                         # ì—£ì§€ ë„¤íŠ¸ì›Œí¬
```

**Step 4: ì˜¤ë””ì˜¤ í ì´ˆê¸°í™”**
```python
# ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ ë°ì´í„° ì €ì¥
self._incoming_audio_queue: AudioQueue = AudioQueue(
    buffer_limit_ms=8000  # 8ì´ˆ ë²„í¼ (ì†ì‹¤ ë°©ì§€)
)

# ì•„ì›ƒí’‹ ì˜¤ë””ì˜¤ íŠ¸ë™
self._audio_track: Optional[OutputAudioTrack] = None

# ë¹„ë””ì˜¤ íŠ¸ë™ ì •ë³´
self._active_video_tracks: Dict[str, TrackInfo] = {}
self._video_forwarders: List[VideoForwarder] = []
```

**Step 5: ì„¤ì • ê²€ì¦**
```python
def _validate_configuration(self):
    """
    ì—ì´ì „íŠ¸ ì„¤ì •ì´ ìœ íš¨í•œì§€ í™•ì¸
    """
    if _is_audio_llm(self.llm):
        # Realtime ëª¨ë“œ: STT/TTS í•„ìš” ì—†ìŒ
        if self.stt or self.tts:
            self.logger.warning(
                "Realtime ëª¨ë“œ ê°ì§€: STT/TTSê°€ ë¬´ì‹œë©ë‹ˆë‹¤"
            )
    else:
        # ì¼ë°˜ ëª¨ë“œ: LLM í•„ìˆ˜
        if self.stt and not self.llm:
            raise ValueError("STT ì‚¬ìš© ì‹œ LLM í•„ìˆ˜")
```

***

### 2.3 Agent ìƒëª… ì£¼ê¸°: join()

```python
@asynccontextmanager
async def join(
    self, 
    call: Call,                              # ì°¸ì—¬í•  í†µí™”
    participant_wait_timeout: Optional[float] = 10.0,  # ì°¸ì—¬ì ëŒ€ê¸°
) -> AsyncIterator[None]:
    """
    í†µí™”ì— ì—ì´ì „íŠ¸ê°€ ì°¸ì—¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
    
    ì‚¬ìš©ë²•:
    async with agent.join(call):
        await agent.finish()  # í†µí™” ì¢…ë£Œ ëŒ€ê¸°
    # ìë™ìœ¼ë¡œ agent.close() í˜¸ì¶œ
    """
```

#### 2.3.1 join() ìƒì„¸ ë‹¨ê³„

**Step 1: ì¤‘ë³µ ì°¸ì—¬ í™•ì¸**
```python
if self._call_ended_event is not None:
    raise RuntimeError("ì—ì´ì „íŠ¸ëŠ” í•œ ë²ˆë§Œ ì°¸ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
```

**Step 2: í†µí™” ì •ë³´ ì„¤ì •**
```python
self.call = call
self._start_tracing(call)  # OpenTelemetry ì‹œì‘

# ë¡œê¹… ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
self._set_call_logging_context(call.id)
```

**Step 3: í”ŒëŸ¬ê·¸ì¸ ì‹œì‘**
```python
# ëª¨ë“  í”ŒëŸ¬ê·¸ì¸ì˜ start() ë©”ì„œë“œ í˜¸ì¶œ
await self._apply("start")

# ì‚¬ìš©ì ìƒì„± (ì—£ì§€ì— ë“±ë¡)
await self.create_user()
```

**Step 4: MCP ì„œë²„ ì—°ê²°**
```python
if self.mcp_manager:
    await self.mcp_manager.connect_all()  # ì™¸ë¶€ ë„êµ¬ ì—°ê²°
```

**Step 5: Realtime LLM ì¤€ë¹„**
```python
if _is_realtime_llm(self.llm):
    await self.llm.connect()  # Gemini/OpenAI Realtime ì¤€ë¹„
```

**Step 6: ì—£ì§€ì— ì°¸ì—¬**
```python
self._connection = await self.edge.join(self, call)
self.logger.info(f"ğŸ¤– ì—ì´ì „íŠ¸ ì°¸ì—¬: {call.id}")
```

**Step 7: ë¯¸ë””ì–´ íŠ¸ë™ ë°œí–‰**
```python
# ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŠ¸ë™ ìƒì„± ë° ë°œí–‰
audio_track = self._audio_track if self.publish_audio else None
video_track = self._video_track if self.publish_video else None

if audio_track or video_track:
    await self.edge.publish_tracks(audio_track, video_track)
```

**Step 8: ì±„íŒ… ì»¨í…ìŠ¤íŠ¸ ìƒì„±**
```python
# LLMì´ ì°¸ì¡°í•  ëŒ€í™” íˆìŠ¤í† ë¦¬ ìƒì„±
self.conversation = await self.edge.create_conversation(
    call, 
    self.agent_user, 
    self.instructions.full_reference
)

# LLMì— ì»¨í…ìŠ¤íŠ¸ ì œê³µ
self.llm.set_conversation(self.conversation)
```

**Step 9: ì°¸ì—¬ì ëŒ€ê¸°**
```python
if participant_wait_timeout != 0:
    await self.wait_for_participant(timeout=participant_wait_timeout)
    # ê¸°ë³¸ 10ì´ˆ ëŒ€ê¸°
```

**Step 10: ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘**
```python
# ë©”ì¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë£¨í”„ ì‹œì‘
self._audio_consumer_task = asyncio.create_task(
    self._consume_incoming_audio()
)

# í†µí™” ì¢…ë£Œ ì‹ í˜¸ ì„¤ì •
self._call_ended_event = asyncio.Event()
self._joined_at = time.time()
```

**Step 11: ì»¨í…ìŠ¤íŠ¸ ì–‘ë³´**
```python
yield  # ì—¬ê¸°ì„œ with ë¸”ë¡ ë‚´ ì½”ë“œ ì‹¤í–‰
```

**Step 12: ì •ë¦¬**
```python
except Exception as exc:
    if self._closing or self._closed:
        logger.warning("ì—ì´ì „íŠ¸ ì¢…ë£Œ ì¤‘...")
    else:
        raise

finally:
    # í†µí™” ì¢…ë£Œ ì‹œ ìë™ ì •ë¦¬
    await self.close()
    self._end_tracing()
    self._join_lock.release()
```

***

### 2.4 í•µì‹¬ ë©”ì„œë“œ: _consume_incoming_audio()

**ë©”ì„œë“œ ìœ„ì¹˜**: Line 1260-1320  
**ëª©ì **: ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ë¥¼ 20ms ê°„ê²©ìœ¼ë¡œ ì²˜ë¦¬

```python
async def _consume_incoming_audio(self) -> None:
    """
    ì˜¤ë””ì˜¤ ì†Œë¹„ ë£¨í”„ (Main Processing Loop)
    
    íŠ¹ì§•:
    âœ“ 20ms ê°„ê²© (50 FPS)
    âœ“ ë¹„ì°¨ë‹¨ (async/await)
    âœ“ 8ì´ˆ ë²„í¼ (ì†ì‹¤ ë°©ì§€)
    """
    interval_seconds = 0.02  # 20ms
    
    while self._call_ended_event and not self._call_ended_event.is_set():
        loop_start = time.perf_counter()
        
        try:
            # 1ï¸âƒ£ ì˜¤ë””ì˜¤ ë°ì´í„° íšë“
            pcm = await asyncio.wait_for(
                self._incoming_audio_queue.get_duration(duration_ms=20),
                timeout=1.0,
            )
            
            participant = pcm.participant
            
            # 2ï¸âƒ£ ì—ì´ì „íŠ¸ ìì‹ ì˜ ìŒì„± ì œì™¸
            if (participant and 
                getattr(participant, "user_id", None) != self.agent_user.id):
                
                # 3ï¸âƒ£ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ (ìŒì„± ê°ì • ë¶„ì„ ë“±)
                for processor in self.audio_processors:
                    if processor is None:
                        continue
                    await processor.process_audio(pcm)
                
                # 4ï¸âƒ£ Realtime LLM ëª¨ë“œ
                if _is_audio_llm(self.llm):
                    await self.simple_audio_response(pcm, participant)
                
                # 5ï¸âƒ£ ì¼ë°˜ STT ëª¨ë“œ
                elif self.stt:
                    await self.stt.process_audio(pcm, participant)
                
                # 6ï¸âƒ£ í„´ ê°ì§€ (ë°œí™” ë ê°ì§€)
                if self.turn_detection is not None and participant is not None:
                    await self.turn_detection.process_audio(
                        pcm, participant, conversation=self.conversation
                    )
        
        except (asyncio.TimeoutError, asyncio.QueueEmpty):
            # ì˜¤ë””ì˜¤ ì—†ìŒ - ê³„ì†
            pass
        
        # 7ï¸âƒ£ ì •í™•í•œ 20ms ê°„ê²© ìœ ì§€
        elapsed = time.perf_counter() - loop_start
        sleep_time = interval_seconds - elapsed
        if sleep_time > 0:
            await asyncio.sleep(sleep_time)
```

**íë¦„ë„:**
```
â”Œâ”€ while ë£¨í”„ ì‹œì‘ (20ms ê°„ê²©)
â”œâ”€ PCM ë°ì´í„° ëŒ€ê¸° (20ms ì²­í¬)
â”‚  â”‚
â”‚  â”œâ”€ ì—ì´ì „íŠ¸ ìì‹ ? â†’ ì œì™¸
â”‚  â”‚
â”‚  â”œâ”€1ï¸âƒ£ Audio Processors
â”‚  â”‚   (ìŒì„± ê°ì •/í’ˆì§ˆ ë¶„ì„)
â”‚  â”‚
â”‚  â”œâ”€2ï¸âƒ£ Realtime LLM?
â”‚  â”‚   ì˜ˆ: simple_audio_response()
â”‚  â”‚   ì•„ë‹ˆì˜¤: ë‹¤ìŒìœ¼ë¡œ
â”‚  â”‚
â”‚  â”œâ”€3ï¸âƒ£ STT ì‹¤í–‰
â”‚  â”‚   (Deepgram STT)
â”‚  â”‚
â”‚  â”œâ”€4ï¸âƒ£ Turn Detection
â”‚  â”‚   (Vogent/SmartTurn)
â”‚  â”‚   ë°œí™” ë? â†’ TurnEndedEvent ë°œí–‰
â”‚  â”‚
â”‚  â””â”€ ì •í™•í•œ 20ms ìŠ¬ë¦½
â””â”€ ë°˜ë³µ
```

***

# Vision-Agents Technical Report

## PART 2-5: ì´ë²¤íŠ¸ ì²˜ë¦¬ ì„¤ì • (Event Handling)

### 2.5 ì´ë²¤íŠ¸ ì²˜ë¦¬ ì„¤ì • (setup_event_handling) - ìƒì„¸ ë¶„ì„

**ë©”ì„œë“œ ìœ„ì¹˜**: Line 119-210  
**ëª©ì **: ëª¨ë“  í”ŒëŸ¬ê·¸ì¸ì˜ ì´ë²¤íŠ¸ë¥¼ ì—ì´ì „íŠ¸ì˜ í†µí•© ì´ë²¤íŠ¸ ë²„ìŠ¤ì— ì—°ê²°

```python
def setup_event_handling(self):
    """
    ì´ë²¤íŠ¸ ì²˜ë¦¬ ì„¤ì •
    
    ì—­í• :
    1. ëª¨ë“  í”ŒëŸ¬ê·¸ì¸ ì´ë²¤íŠ¸ë¥¼ êµ¬ë…
    2. ì´ë²¤íŠ¸ ê°„ ì˜ì¡´ì„± ì—°ê²°
    3. ì½œë°± í•¨ìˆ˜ ë“±ë¡
    
    íŠ¹ì§•:
    âœ“ ë””ì»¤í”Œë§ëœ ì•„í‚¤í…ì²˜
    âœ“ ë¹„ë™ê¸° ì²˜ë¦¬ (@async)
    âœ“ ìë™ ì—ëŸ¬ ì²˜ë¦¬
    """
    
    # 1ï¸âƒ£ í„´ ê°ì§€ ì´ë²¤íŠ¸ êµ¬ë…
    self.events.subscribe(self._on_turn_event)
```

#### 2.5.1 í„´ ê°ì§€ ì´ë²¤íŠ¸ êµ¬ë…

```python
@self.events.subscribe
async def _on_turn_event(self, event: TurnStartedEvent | TurnEndedEvent) -> None:
    """
    ë°œí™” ì‹œì‘/ì¢…ë£Œ ê°ì§€
    
    TurnStartedEvent:
    â”œâ”€ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì‹œì‘
    â”œâ”€ TTS ì¤‘ë‹¨ (Barge-in)
    â””â”€ ìƒˆ í„´ ì¤€ë¹„
    
    TurnEndedEvent:
    â”œâ”€ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì¢…ë£Œ
    â”œâ”€ ë¶€ë¶„ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ
    â””â”€ LLM ì‘ë‹µ íŠ¸ë¦¬ê±°
    """
    
    # Realtime LLM ëª¨ë“œëŠ” ìì²´ ì²˜ë¦¬
    if _is_audio_llm(self.llm):
        return
    
    if isinstance(event, TurnStartedEvent):
        # âŒ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì‹œì‘ â†’ TTS ì¤‘ë‹¨
        if event.participant and event.participant.user_id != self.agent_user.id:
            if self.tts:
                await self.tts.stop_audio()  # ìŒì„± ì¤‘ë‹¨ (Barge-in)
                
    elif isinstance(event, TurnEndedEvent):
        # âœ… ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì¢…ë£Œ â†’ LLM ì‘ë‹µ ì¤€ë¹„
        
        # ì—ì´ì „íŠ¸ ìì‹ ì€ ì œì™¸
        if not event.participant or event.participant.user_id == self.agent_user.id:
            return
        
        # ë¶€ë¶„ í…ìŠ¤íŠ¸ ë²„í¼ì—ì„œ ìµœì¢… í…ìŠ¤íŠ¸ ì¶”ì¶œ
        buffer = self._pending_user_transcripts[event.participant.user_id]
        
        # STTê°€ ë”°ë¼ì¡ê¸° ìœ„í•´ ì ì‹œ ëŒ€ê¸°
        if not event.eager_end_of_turn:
            if self.stt:
                await self.stt.clear()
            await asyncio.sleep(0.02)  # 20ms ëŒ€ê¸°
        
        # ìµœì¢… í…ìŠ¤íŠ¸ íšë“
        transcript = buffer.text
        
        if not event.eager_end_of_turn:
            buffer.reset()
        
        # í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ LLM í˜¸ì¶œ
        if transcript.strip():
            # ìƒˆ LLM í„´ ìƒì„±
            if self._pending_turn is None or self._pending_turn.input != transcript:
                llm_turn = LLMTurn(
                    input=transcript,
                    participant=event.participant,
                    started_at=datetime.datetime.now(),
                    turn_finished=not event.eager_end_of_turn,
                )
                self._pending_turn = llm_turn
                
                # LLM ë¹„ë™ê¸° í˜¸ì¶œ
                task = asyncio.create_task(
                    self.simple_response(transcript, event.participant)
                )
                llm_turn.task = task
```

**ì‹œê°ì  íë¦„:**
```
ì‚¬ìš©ì ìŒì„±
    â”‚
    â–¼
STT: "ì•ˆë…•í•˜ì„¸ìš”"
    â”‚
    â”œâ”€ TurnStartedEvent
    â”‚  â””â”€ TTS ì¤‘ë‹¨ âŒ
    â”‚
    â””â”€ (ì§€ì† ìŒì„± ì¸ì‹)
    
ì‚¬ìš©ì ìŒì„± ì¢…ë£Œ
    â”‚
    â–¼
TurnEndedEvent
    â”‚
    â”œâ”€ ìµœì¢… í…ìŠ¤íŠ¸: "ì•ˆë…•í•˜ì„¸ìš”"
    â”œâ”€ LLM.simple_response() í˜¸ì¶œ
    â”‚  â””â”€ OpenAI/Gemini/Claude API
    â”‚
    â””â”€ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...
```

***

#### 2.5.2 LLM ì‘ë‹µ ì™„ë£Œ ì´ë²¤íŠ¸

```python
@self.llm.events.subscribe
async def on_llm_response_send_to_tts(event: LLMResponseCompletedEvent):
    """
    LLM ì‘ë‹µ ì™„ë£Œ â†’ TTSë¡œ ìŒì„± í•©ì„±
    
    ìƒí™© 1: ì™¸ë¶€ í˜¸ì¶œ (agent.say())
    â”œâ”€ self._pending_turnì´ None
    â”œâ”€ TTSì— ì§ì ‘ ì „ë‹¬
    â””â”€ ì˜ˆ: agent.say("ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”?")
    
    ìƒí™© 2: ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ
    â”œâ”€ self._pending_turn ì¡´ì¬
    â”œâ”€ í„´ ì •ë³´ ì €ì¥
    â””â”€ í„´ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
    """
    
    if self._pending_turn is None:
        # ì™¸ë¶€ í˜¸ì¶œ (agent.say())
        if self.tts and event.text and event.text.strip():
            sanitized_text = self._sanitize_text(event.text)
            await self.tts.send(sanitized_text)
    else:
        # ì‚¬ìš©ì ì…ë ¥ ì‘ë‹µ
        self._pending_turn.response = event
        
        if self._pending_turn.turn_finished:
            # í„´ ì™„ë£Œ â†’ TTS ë°œí–‰
            await self._finish_llm_turn()
        else:
            # Eager ëª¨ë“œ - í™•ì¸ ëŒ€ê¸°
            pass
```

**ì½”ë“œ íë¦„:**
```python
# ìƒí™© 1: ì™¸ë¶€ í˜¸ì¶œ
agent.say("ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”?")
    â”‚
    â”œâ”€ AgentSayEvent ë°œí–‰
    â”‚
    â””â”€ _on_agent_say() í˜¸ì¶œ
       â””â”€ TTS.send() í˜¸ì¶œ
          â””â”€ TTSAudioEvent ë°œí–‰
             â””â”€ OutputAudioTrackì— ê¸°ë¡

# ìƒí™© 2: ì‚¬ìš©ì ì‘ë‹µ
ì‚¬ìš©ì: "ì•ˆë…•í•˜ì„¸ìš”"
    â”‚
    â”œâ”€ TurnEndedEvent
    â”‚  â””â”€ simple_response() í˜¸ì¶œ
    â”‚
    â”œâ”€ LLM API í˜¸ì¶œ
    â”‚  â””â”€ "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    â”‚
    â””â”€ LLMResponseCompletedEvent
       â””â”€ TTS.send() í˜¸ì¶œ
          â””â”€ ìŒì„± í•©ì„±
```

***

#### 2.5.3 TTS ì˜¤ë””ì˜¤ ì¶œë ¥ íŠ¸ë™ ê¸°ë¡

```python
@self.events.subscribe
async def _on_tts_audio_write_to_output(event: TTSAudioEvent):
    """
    TTS í•©ì„± ì˜¤ë””ì˜¤ â†’ ì¶œë ¥ íŠ¸ë™ì— ê¸°ë¡
    
    ì²˜ë¦¬:
    1. TTSê°€ ì˜¤ë””ì˜¤ ì²­í¬ ìƒì„±
    2. OutputAudioTrackì— ê¸°ë¡
    3. WebRTC â†’ í´ë¼ì´ì–¸íŠ¸ì— ì „ë‹¬
    """
    if self._audio_track is not None:
        # PCM ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì¶œë ¥ íŠ¸ë™ì— ê¸°ë¡
        await self._audio_track.write(event.data)
```

**ì˜¤ë””ì˜¤ íë¦„:**
```
TTSAudioEvent (PCM ì²­í¬)
    â”‚
    â”œâ”€ 8kHz, 16ë¹„íŠ¸, ëª¨ë…¸
    â”œâ”€ 20ms ì²­í¬ (~160 ìƒ˜í”Œ)
    â”‚
    â””â”€ _audio_track.write(pcm)
       â”‚
       â”œâ”€ ë‚´ë¶€ ë²„í¼ì— ì €ì¥
       â”œâ”€ WebRTC ì¸ì½”ë”©
       â”‚
       â””â”€ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡ (RTP)
```

***

#### 2.5.4 ë¹„ë””ì˜¤ íŠ¸ë™ ì¶”ê°€/ì œê±°

```python
@self.edge.events.subscribe
async def on_video_track_added(event: TrackAddedEvent | TrackRemovedEvent):
    """
    ë¹„ë””ì˜¤ íŠ¸ë™ ì¶”ê°€/ì œê±° ê°ì§€
    
    TrackAddedEvent:
    â”œâ”€ ì›ê²© ì°¸ì—¬ìì˜ ë¹„ë””ì˜¤ ì¶”ê°€
    â”œâ”€ ìš°ì„ ìˆœìœ„: ScreenShare > Camera
    â””â”€ ë¹„ë””ì˜¤ í”„ë¡œì„¸ì„œì— ì—°ê²°
    
    TrackRemovedEvent:
    â”œâ”€ ì›ê²© ì°¸ì—¬ì ë‚˜ê°
    â””â”€ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    """
    
    if event.track_id is None or event.track_type is None:
        return
    
    if isinstance(event, TrackRemovedEvent):
        asyncio.create_task(
            self._on_track_removed(event.track_id, event.track_type, event.user)
        )
    else:
        asyncio.create_task(
            self._on_track_added(event.track_id, event.track_type, event.user)
        )
```

***

#### 2.5.5 ì˜¤ë””ì˜¤ ìˆ˜ì‹  ì´ë²¤íŠ¸

```python
@self.edge.events.subscribe
async def on_audio_received(event: AudioReceivedEvent):
    """
    ì›ê²© ì°¸ì—¬ìì˜ ì˜¤ë””ì˜¤ ìˆ˜ì‹ 
    
    ì²˜ë¦¬:
    1. PCM ë°ì´í„° ì¶”ì¶œ
    2. ì˜¤ë””ì˜¤ íì— ì €ì¥
    3. _consume_incoming_audio()ì—ì„œ ì²˜ë¦¬
    """
    if event.pcm_data is None:
        return
    
    # 8ì´ˆ ë²„í¼ì— ì €ì¥ (ì†ì‹¤ ë°©ì§€)
    await self._incoming_audio_queue.put(event.pcm_data)
```

***

#### 2.5.6 í†µí™” ì¢…ë£Œ ì´ë²¤íŠ¸

```python
@self.edge.events.subscribe
async def on_call_ended(event: CallEndedEvent):
    """
    í†µí™” ì¢…ë£Œ ê°ì§€
    
    ì²˜ë¦¬:
    1. ì¢…ë£Œ ì‹ í˜¸ ì„¤ì •
    2. ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
    3. ëª¨ë“  ë¦¬ì†ŒìŠ¤ í•´ì œ
    """
    if self._call_ended_event is not None:
        self._call_ended_event.set()  # ì¢…ë£Œ ì‹ í˜¸
    
    await self.close()  # ì •ë¦¬
```

***

### 2.6 STT ì´ë²¤íŠ¸ ì²˜ë¦¬

#### 2.6.1 STT íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì´ë²¤íŠ¸

```python
@self.events.subscribe
async def on_stt_transcript_event_create_response(
    event: STTTranscriptEvent | STTPartialTranscriptEvent,
):
    """
    STT ê²°ê³¼ ì²˜ë¦¬
    
    STTPartialTranscriptEvent: "ì•ˆë…•í•˜"
    STTTranscriptEvent:        "ì•ˆë…•í•˜ì„¸ìš”"
    
    ì²˜ë¦¬:
    1. Realtime LLM ëª¨ë“œ í™•ì¸
    2. ë¶€ë¶„/ìµœì¢… í…ìŠ¤íŠ¸ ëˆ„ì 
    3. í„´ ì™„ë£Œ ì‹ í˜¸ ëŒ€ê¸° ë˜ëŠ” íŠ¸ë¦¬ê±°
    """
    
    # Realtime LLMì€ ìì²´ ì²˜ë¦¬
    if _is_audio_llm(self.llm):
        return
    
    user_id = event.user_id()
    
    if isinstance(event, STTPartialTranscriptEvent):
        self.logger.info(f"ğŸ¤ [ë¶€ë¶„]: {event.text}")
    else:
        self.logger.info(f"ğŸ¤ [ì™„ë£Œ]: {event.text}")
    
    # ì‚¬ìš©ìë³„ ë²„í¼ì— ì €ì¥
    self._pending_user_transcripts[user_id].update(event)
    
    # í„´ ê°ì§€ ì—†ìœ¼ë©´ ì¦‰ì‹œ íŠ¸ë¦¬ê±°
    if not self.turn_detection_enabled and isinstance(
        event, STTTranscriptEvent
    ):
        self.events.send(
            TurnEndedEvent(
                participant=event.participant,
            )
        )
```

**ìƒíƒœ ë‹¤ì´ì–´ê·¸ë¨:**
```
STT ì¸ì‹ ì§„í–‰
    â”‚
    â”œâ”€ "ì•ˆë…•"         â† STTPartialTranscriptEvent
    â”œâ”€ "ì•ˆë…•í•˜"       â† STTPartialTranscriptEvent
    â”œâ”€ "ì•ˆë…•í•˜ì„¸"     â† STTPartialTranscriptEvent
    â””â”€ "ì•ˆë…•í•˜ì„¸ìš”"   â† STTTranscriptEvent (ìµœì¢…)
       â”‚
       â”œâ”€ í„´ ê°ì§€ í™œì„±í™”?
       â”‚  ì˜ˆ: TurnEndedEvent ëŒ€ê¸°
       â”‚  ì•„ë‹ˆì˜¤: TurnEndedEvent ìƒì„± â†’ ì¦‰ì‹œ LLM
       â”‚
       â””â”€ LLM í˜¸ì¶œ
```

***

### 2.7 LLM ì‘ë‹µ ë™ê¸°í™”

#### 2.7.1 ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ê¸°ë¡

```python
@self.llm.events.subscribe
async def on_llm_response_sync_conversation(event: LLMResponseCompletedEvent):
    """
    LLM ì‘ë‹µì„ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì €ì¥
    
    ëª©ì :
    1. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
    2. ë‹¤ìŒ LLM í˜¸ì¶œì— í™œìš©
    3. ê°ì‚¬ ë¡œê·¸ ìƒì„±
    """
    
    if event.text:
        self.logger.info(f"ğŸ¤– [LLM]: {event.text}")
    
    if self.conversation is None:
        return
    
    await self.conversation.upsert_message(
        message_id=event.item_id,
        role="assistant",
        user_id=self.agent_user.id or "agent",
        content=event.text or "",
        completed=True,
        replace=True,  # ë¶€ë¶„ ì‘ë‹µ ë®ì–´ì“°ê¸°
    )
```

***

# Vision-Agents Technical Report

## PART 2-8: ì‹¤ì‹œê°„ ëª¨ë“œ ì´ë²¤íŠ¸ (Realtime LLM Events)

### 2.8 Realtime ëª¨ë“œ ì „ìš© ì´ë²¤íŠ¸ ì²˜ë¦¬

Realtime ëª¨ë“œ (Gemini Live, OpenAI Realtime)ëŠ” ìŒì„±/ì˜ìƒì„ ì§ì ‘ ì²˜ë¦¬í•˜ë¯€ë¡œ STT/TTSê°€ ì—†ìŠµë‹ˆë‹¤.

#### 2.8.1 ì‚¬ìš©ì ìŒì„± ì „ì‚¬ ì´ë²¤íŠ¸

```python
@self.events.subscribe
async def on_realtime_user_speech_transcription(
    event: RealtimeUserSpeechTranscriptionEvent,
):
    """
    Realtime LLMì´ ì‚¬ìš©ì ìŒì„±ì„ ì¸ì‹í•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    íŠ¹ì§•:
    â”œâ”€ LLMì´ ì§ì ‘ ì²˜ë¦¬ (STT ì—†ìŒ)
    â”œâ”€ ìë™ ìŒì„± ì¸ì‹
    â”œâ”€ ë¶€ë¶„ â†’ ìµœì¢… ì „ì‚¬
    â””â”€ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì €ì¥
    
    ì˜ˆì‹œ:
    ì‚¬ìš©ì: "ë‚ ì”¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
         â†“
    LLM: "ë‚ ì”¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?" (ì „ì‚¬)
         â†“
    ì±„íŒ…ì— ê¸°ë¡
    """
    
    self.logger.info(f"ğŸ¤ [ì‚¬ìš©ì ìŒì„±]: {event.text}")
    
    if self.conversation is None or not event.text:
        return
    
    if user_id := event.user_id():
        with self.span("agent.on_realtime_user_speech_transcription"):
            # ì±„íŒ… ì»¨í…ìŠ¤íŠ¸ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            await self.conversation.upsert_message(
                message_id=str(uuid.uuid4()),
                role="user",                    # ì‚¬ìš©ì ë©”ì‹œì§€
                user_id=user_id,
                content=event.text,
                completed=True,
                replace=True,  # ë¶€ë¶„ ì¸ì‹ ë®ì–´ì“°ê¸°
                original=event,
            )
    else:
        self.logger.info(
            "ì‚¬ìš©ì IDê°€ ì—†ì–´ ì±„íŒ…ì— ê¸°ë¡í•˜ì§€ ì•ŠìŒ"
        )
```

**ì²˜ë¦¬ íë¦„:**
```
ì‚¬ìš©ì ìŒì„±
    â”‚
    â–¼
Gemini/OpenAI Realtime
    â”‚
    â”œâ”€ ìŒì„± ì²˜ë¦¬ (ìì²´ STT)
    â”‚
    â”œâ”€ "ë‚ ì”¨"        â† ë¶€ë¶„ (ìë™ ë¬´ì‹œ)
    â”œâ”€ "ë‚ ì”¨ê°€"      â† ë¶€ë¶„ (ìë™ ë¬´ì‹œ)
    â””â”€ "ë‚ ì”¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"  â† ìµœì¢…
       â”‚
       â–¼
    RealtimeUserSpeechTranscriptionEvent
       â”‚
       â”œâ”€ ë¡œê¹…
       â”œâ”€ ì±„íŒ… ì €ì¥
       â””â”€ LLMì´ ì´ë¯¸ ì´í•´í•¨ (ë‹¤ìŒ ì‘ë‹µ ì¤€ë¹„)
```

***

#### 2.8.2 ì—ì´ì „íŠ¸ ìŒì„± ì „ì‚¬ ì´ë²¤íŠ¸

```python
@self.events.subscribe
async def on_realtime_agent_speech_transcription(
    event: RealtimeAgentSpeechTranscriptionEvent,
):
    """
    Realtime LLMì´ ìƒì„±í•œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    íŠ¹ì§•:
    â”œâ”€ LLMì˜ ìŒì„± í•©ì„± ê²°ê³¼
    â”œâ”€ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±ë¨
    â”œâ”€ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì €ì¥
    â””â”€ ì‚¬ìš©ìì—ê²Œ ì´ë¯¸ ì¬ìƒ ì¤‘
    
    ì˜ˆì‹œ:
    LLMì´ ìƒê° ì¤‘...
         â†“
    "í˜„ì¬ ì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ê³  ì˜í•˜ 2ë„ì…ë‹ˆë‹¤"
         â†“
    ìŒì„±ìœ¼ë¡œ ì¬ìƒ ì¤‘
         â†“
    í…ìŠ¤íŠ¸ë¡œ ì €ì¥
    """
    
    self.logger.info(f"ğŸ¤– [ì—ì´ì „íŠ¸ ìŒì„±]: {event.text}")
    
    if self.conversation is None or not event.text:
        return
    
    with self.span("agent.on_realtime_agent_speech_transcription"):
        # ì±„íŒ… ì»¨í…ìŠ¤íŠ¸ì— ì—ì´ì „íŠ¸ ë©”ì‹œì§€ ì €ì¥
        await self.conversation.upsert_message(
            message_id=str(uuid.uuid4()),
            role="assistant",                  # ì—ì´ì „íŠ¸ ë©”ì‹œì§€
            user_id=self.agent_user.id or "",
            content=event.text,
            completed=True,
            replace=True,  # ë¶€ë¶„ ì‘ë‹µ ë®ì–´ì“°ê¸°
            original=event,
        )
```

**Realtime LLMê³¼ì˜ ëŒ€í™”:**
```
â”Œâ”€ ì‚¬ìš©ì: "ì•ˆë…•í•˜ì„¸ìš”"
â”‚
â”œâ”€ LLM ì²˜ë¦¬ (ë‚´ë¶€)
â”‚  â”œâ”€ ì‚¬ìš©ì ìŒì„± ì¸ì‹
â”‚  â””â”€ ì‘ë‹µ ìƒì„± ì¤‘
â”‚
â”œâ”€ RealtimeUserSpeechTranscriptionEvent
â”‚  â””â”€ "ì•ˆë…•í•˜ì„¸ìš”" ì €ì¥
â”‚
â”œâ”€ LLM ì‘ë‹µ ìƒì„± ì‹œì‘
â”‚  â””â”€ ìŒì„± í•©ì„± ì‹œì‘
â”‚
â”œâ”€ RealtimeAgentSpeechTranscriptionEvent (ìŠ¤íŠ¸ë¦¬ë°)
â”‚  â”œâ”€ "ì•ˆë…•"      (ë¶€ë¶„)
â”‚  â”œâ”€ "ì•ˆë…•í•˜ì„¸"  (ë¶€ë¶„)
â”‚  â””â”€ "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"  (ìµœì¢…)
â”‚     â””â”€ ì €ì¥ (replace=Trueë¡œ ë®ì–´ì“°ê¸°)
â”‚
â””â”€ ì‚¬ìš©ìì—ê²Œ ìŒì„±ìœ¼ë¡œ ì¬ìƒ ì¤‘
```

***

#### 2.8.3 Realtime ì˜¤ë””ì˜¤ ì¶œë ¥ ì´ë²¤íŠ¸

```python
@self.events.subscribe
async def forward_audio(event: RealtimeAudioOutputEvent):
    """
    Realtime LLMì´ ìƒì„±í•œ ì˜¤ë””ì˜¤ â†’ ì¶œë ¥ íŠ¸ë™
    
    ì²˜ë¦¬:
    1. LLMì´ ìŒì„± í•©ì„±
    2. PCM ì²­í¬ ìƒì„±
    3. OutputAudioTrackì— ê¸°ë¡
    4. WebRTC â†’ í´ë¼ì´ì–¸íŠ¸
    """
    if self._audio_track is not None:
        await self._audio_track.write(event.data)
```

**ì˜¤ë””ì˜¤ ë°ì´í„° íë¦„:**
```
LLM: "ì•ˆë…•í•˜ì„¸ìš”"
    â”‚
    â”œâ”€ ìŒì„± í•©ì„± (TTS)
    â”‚
    â””â”€ PCM ì²­í¬ ìƒì„±
       â”œâ”€ ì²­í¬ 1: ì•ˆë…• (20ms)
       â”œâ”€ ì²­í¬ 2: í•˜ì„¸ (20ms)
       â””â”€ ì²­í¬ 3: ìš”   (20ms)
          â”‚
          â–¼
       RealtimeAudioOutputEvent ë°œí–‰
          â”‚
          â”œâ”€ forward_audio() í˜¸ì¶œ
          â”‚
          â”œâ”€ _audio_track.write(pcm)
          â”‚
          â”œâ”€ WebRTC ì¸ì½”ë”©
          â”‚
          â””â”€ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
             â””â”€ ì‚¬ìš©ì ìŠ¤í”¼ì»¤ì—ì„œ ì¬ìƒ
```

***

### 2.9 LLM ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬

#### 2.9.1 LLM ì‘ë‹µ ì²­í¬ ì´ë²¤íŠ¸

```python
@self.llm.events.subscribe
async def _handle_output_text_delta(event: LLMResponseChunkEvent):
    """
    LLMì´ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë™ì•ˆ
    ë¶€ë¶„ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë°›ìŒ
    
    íŠ¹ì§•:
    â”œâ”€ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
    â”œâ”€ ìµœì¢… ì™„ì„±ë˜ê¸° ì „
    â”œâ”€ ì±„íŒ… ì—…ë°ì´íŠ¸
    â””â”€ ì‚¬ìš©ìê°€ ì‘ë‹µì„ ë³´ëŠ” ì¤‘
    
    ì˜ˆì‹œ:
    ì‚¬ìš©ì: "íŒŒì´ì¬ ì„¤ëª…í•´ì¤˜"
    
    ì²­í¬ 1: "íŒŒì´ì¬ì€"
    ì²­í¬ 2: "íŒŒì´ì¬ì€ ê³ ê¸‰"
    ì²­í¬ 3: "íŒŒì´ì¬ì€ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤"
    """
    
    if self.conversation is None:
        return
    
    with self.span("agent._handle_output_text_delta"):
        # ë¶€ë¶„ ì‘ë‹µì„ ì±„íŒ…ì— ì—…ë°ì´íŠ¸
        await self.conversation.upsert_message(
            message_id=event.item_id,
            role="assistant",
            user_id=self.agent_user.id or "agent",
            content=event.delta or "",          # ë¶€ë¶„ í…ìŠ¤íŠ¸
            content_index=event.content_index,
            completed=False,                    # ì•„ì§ ì§„í–‰ ì¤‘
        )
```

**ìŠ¤íŠ¸ë¦¬ë° ì‹œê°í™”:**
```
LLM ì‘ë‹µ ìƒì„± ì¤‘...

ì‹œì  1 (0ms):
ì±„íŒ…: [Assistant] íŒŒì´ì¬

ì‹œì  2 (50ms):
ì±„íŒ…: [Assistant] íŒŒì´ì¬ì€

ì‹œì  3 (100ms):
ì±„íŒ…: [Assistant] íŒŒì´ì¬ì€ ê³ ê¸‰

ì‹œì  4 (150ms):
ì±„íŒ…: [Assistant] íŒŒì´ì¬ì€ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤
                    â†‘
              ì™„ë£Œë¨ (completed=True)
```

***

### 2.10 ì—ëŸ¬ ì²˜ë¦¬

#### 2.10.1 STT ì—ëŸ¬ ì´ë²¤íŠ¸

```python
@self.events.subscribe
async def on_error(event: STTErrorEvent):
    """
    STT ì²˜ë¦¬ ì¤‘ ë°œìƒí•œ ì—ëŸ¬ ì²˜ë¦¬
    
    ì¼ë°˜ì ì¸ ì—ëŸ¬:
    â”œâ”€ ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨
    â”œâ”€ ìŒì„± í’ˆì§ˆ ë‚®ìŒ
    â”œâ”€ íƒ€ì„ì•„ì›ƒ
    â””â”€ API ì˜¤ë¥˜
    """
    self.logger.error("STT ì—ëŸ¬ ë°œìƒ: %s", event)
    
    # ì—ëŸ¬ ë³µêµ¬:
    # 1. ì¬ì‹œë„ ë¡œì§
    # 2. ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
    # 3. í´ë°± ì²˜ë¦¬
```

***

### 2.11 VideoProcessor ì´ë²¤íŠ¸

#### 2.11.1 ë¹„ë””ì˜¤ íŠ¸ë™ ì²˜ë¦¬

```python
async def _track_to_video_processors(self, track: TrackInfo):
    """
    ë¹„ë””ì˜¤ íŠ¸ë™ â†’ í”„ë¡œì„¸ì„œ íŒŒì´í”„ë¼ì¸
    
    ì²˜ë¦¬:
    1. YOLO (ê°ì²´/ìì„¸ ê°ì§€)
    2. Roboflow (ì»¤ìŠ¤í…€ ê°ì§€)
    3. Moondream VLM (ì˜ìƒ ì´í•´)
    4. ê²°ê³¼ ìˆ˜ì§‘ â†’ LLMì— ì „ë‹¬
    """
    
    for processor in self.video_processors:
        try:
            user_id = track.participant.user_id if track.participant else None
            
            # ë¹„ë””ì˜¤ í”„ë¡œì„¸ì„œì— íŠ¸ë™ ì „ë‹¬
            await processor.process_video(
                track.track,                    # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼
                user_id,
                shared_forwarder=track.forwarder  # ë²„í¼ ê³µìœ 
            )
        
        except Exception as e:
            self.logger.error(
                f"ë¹„ë””ì˜¤ í”„ë¡œì„¸ì„œ ì—ëŸ¬ ({type(processor).__name__}): {e}"
            )
```

**ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:**
```
ì›ê²© ì°¸ì—¬ì ë¹„ë””ì˜¤
    â”‚
    â–¼
VideoForwarder (30 FPS ë²„í¼)
    â”‚
    â”œâ”€ YOLO í”„ë¡œì„¸ì„œ
    â”‚  â”œâ”€ ì‚¬ëŒ ê°ì§€
    â”‚  â”œâ”€ ìì„¸ ê°ì§€
    â”‚  â””â”€ {x: 100, y: 150, class: "person"} ë°˜í™˜
    â”‚
    â”œâ”€ Roboflow í”„ë¡œì„¸ì„œ
    â”‚  â”œâ”€ íŒ¨í‚¤ì§€ ê°ì§€
    â”‚  â””â”€ {id: 1, confidence: 0.95} ë°˜í™˜
    â”‚
    â””â”€ Moondream VLM
       â”œâ”€ ì˜ìƒ ì´í•´
       â””â”€ "ì‚¬ëŒì´ íŒ¨í‚¤ì§€ë¥¼ ì§‘ì–´ì˜¬ë¦¬ëŠ” ì¤‘" ë°˜í™˜
          â”‚
          â–¼
       LLMì— ìƒíƒœ ì •ë³´ ì „ë‹¬
          â”‚
          â””â”€ simple_response()ì— í¬í•¨
```

***

### 2.12 ì´ë²¤íŠ¸ ì²´ì¸ ìš”ì•½

**ì™„ì „í•œ ì´ë²¤íŠ¸ ì²´ì¸:**

```
ì‚¬ìš©ì ì…ë ¥ (ìŒì„±/ë¹„ë””ì˜¤)
    â”‚
    â”œâ”€ ğŸ¤ AudioReceivedEvent
    â”‚  â””â”€ _incoming_audio_queueì— ì €ì¥
    â”‚
    â”œâ”€ _consume_incoming_audio()
    â”‚  â”‚
    â”‚  â”œâ”€1ï¸âƒ£ AudioProcessor
    â”‚  â”‚
    â”‚  â”œâ”€2ï¸âƒ£ STT.process_audio()
    â”‚  â”‚   â””â”€ STTTranscriptEvent ë°œí–‰
    â”‚  â”‚
    â”‚  â””â”€3ï¸âƒ£ TurnDetection
    â”‚      â””â”€ TurnEndedEvent ë°œí–‰
    â”‚
    â”œâ”€ _on_turn_event()
    â”‚  â””â”€ simple_response(text, participant) í˜¸ì¶œ
    â”‚
    â”œâ”€ ğŸ¤– LLM API í˜¸ì¶œ
    â”‚  â”œâ”€ OpenAI/Gemini/Claude
    â”‚  â””â”€ í”„ë¡œì„¸ì„œ ìƒíƒœ í¬í•¨
    â”‚
    â”œâ”€ LLMResponseCompletedEvent ìˆ˜ì‹ 
    â”‚  â”‚
    â”‚  â”œâ”€ on_llm_response_send_to_tts()
    â”‚  â”‚  â””â”€ TTS.send(text) í˜¸ì¶œ
    â”‚  â”‚
    â”‚  â””â”€ on_llm_response_sync_conversation()
    â”‚     â””â”€ ì±„íŒ…ì— ì €ì¥
    â”‚
    â”œâ”€ TTSAudioEvent ìˆ˜ì‹ 
    â”‚  â””â”€ _on_tts_audio_write_to_output()
    â”‚     â””â”€ _audio_track.write(pcm)
    â”‚
    â””â”€ ğŸ”Š í´ë¼ì´ì–¸íŠ¸ê°€ ìŒì„± ì¬ìƒ
```

***

